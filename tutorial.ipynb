{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54706956",
   "metadata": {},
   "source": [
    "# Simulations for Clustered Switchback Experiments\n",
    "<a id='toc'></a>\n",
    "\n",
    "## Table of Contents \n",
    "[Section 1: Model](#sec1)\n",
    "\n",
    "[Section 2: Step by Step Guide](#step_by_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4116f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, importlib, sys, os, pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set up directory\n",
    "current_dir = os.getcwd() # Get current directory\n",
    "print(\"current dir:\", current_dir)\n",
    "\n",
    "parent_dir = os.path.dirname(current_dir) # Go up by one level\n",
    "sys.path.append(parent_dir) # Add parent dir to sys path\n",
    "\n",
    "from helpers import utils, graph_helpers, mdp_helpers, stats_helpers, print_nicely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141be9b8",
   "metadata": {},
   "source": [
    "## 1. Model <a id='sec1'></a> \n",
    "We will use a linear reward function\n",
    "$$\\mu_{it}(S_{it}): = E[Y_{it} \\mid S_{it}, W] = a_{i} + b_{it} S_{it}.$$\n",
    "We choose $a_{i} \\sim U[0,1]$, and $b_{it} = (1 + 0.2 \\epsilon_{it})/m_i$, where $\\epsilon_{it} \\sim U[0,1]$.\n",
    "\n",
    "The state evolves as a clipped random walk with states $\\{0,1,...,m_i\\}$. Specifially, define *competition level* as the proportion of neighbors assigned arm $1$, formally,  \n",
    "$$C_{it} = \\frac{\\sum_{j\\in {\\cal N}(i)\\backslash i}W_{jt}}{|{\\cal N}(i)\\backslash i|}.$$\n",
    "\n",
    "At each time $t$, with probability $\\lambda^l_{it}$, the state does not change. We choose $\\lambda^l_{it} = 0.1$.\n",
    "\n",
    "Conditioned on the event that the state changes, the departure and arrival rates are governed by parameters $\\lambda^d_{it} \\sim U[0,1]$ and $$\\lambda^a_{it} = \\sigma (\\alpha_{it} + \\beta_{it} W_{it} - \\gamma{it} C_{it}),$$ where $\\sigma(\\cdot)$ denotes the sigmoid function. We choose $\\alpha_{it} \\sim N(-5,2)$, $\\beta_{it} \\sim N(10,4)$, $\\gamma_{it} \\sim U[0,\\beta_{it}/2]$.\n",
    "\n",
    "Conditioned on the event that the state changes, the probability of a departure (state decreasing)is $\\lambda^d_{it}/(\\lambda^a_{it} + \\lambda^d_{it})$, and the probability of an arrival (state increasing) is $\\lambda^a_{it}/(\\lambda^a_{it} + \\lambda^d_{it})$. The states are then clipped to be within $\\{0,1,2, \\dots m_i\\}$.\n",
    "\n",
    "By construction $\\gamma_{it} \\leq \\beta_{it}$ such that under full treatment the net effect is still positive.\n",
    "\n",
    "For a given $\\delta$, the exposure mapping is computed as \n",
    "$$\\prod_{t' = t-r}^{t} \\mathbb{I}\\Big(W_{it} = a, \\sum_{j\\in {\\cal N}(i)\\backslash i}\\mathbb{I}(W_{jt} = a) \\geq (1-\\delta) |{\\cal N}(i)\\backslash i|\\Big).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0478606",
   "metadata": {},
   "source": [
    "<a id='step_by_step'></a> \n",
    "\n",
    "## 2. Step-by-step guide\n",
    "\n",
    "We now combine the components in the above sections.\n",
    "Pipeline:\n",
    "1. Define instance (interference graph, reward func, transition probability)\n",
    "2. Generate treatment assignment W\n",
    "3. Run the MDP induced by W\n",
    "4. estimate ATE using HT estimator\n",
    "\n",
    "Back to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8ed86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_config = {\n",
    "    \"T\": 1000, # time horizon\n",
    "    \"num_states\": 30, # maximum inventory\n",
    "    'time_block_length': int(30*np.log(1000)), # length of time blocks used for randomized design\n",
    "    \"recency\": int(30*np.log(1000)), # how many rounds to look back in HT/Hajek estimator \n",
    "    \"delta\": 0.2, #  expo map X_ita^r = 1 if more than 1-delta spatio-temp neighbors are assigned arm a\n",
    "    'num_W_for_computing_prop': 10**4, # num of trtmt asgn mtx used for finding prop score (monte carlo) \n",
    "    'initial_state': 15\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae1a145",
   "metadata": {},
   "source": [
    "## 2.1: Setup interference graph and spatial clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337421cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(graph_helpers)\n",
    "# importlib.reload(stats_helpers)\n",
    "\n",
    "# ########## STRICT LATTICE GRAPH ##########\n",
    "\n",
    "# sim_config.update({\n",
    "#     \"n\": 1, # if constructing a strict lattice graph, this quantity must be a perfect square\n",
    "#     'num_cells_per_dim': 1, # defines spatial block for randomized design\n",
    "#     \"kappa\": 3, # two nodes interfere (thru reward and transition) if L1 dist <= kappa \n",
    "# })\n",
    "\n",
    "# # create interference graph\n",
    "# adj_matrix = graph_helpers.generate_interference_graph_from_lattice(\n",
    "#     sqrt_n=int(np.sqrt(sim_config['n'])), \n",
    "#     kappa=sim_config['kappa']\n",
    "#     )\n",
    "# print(np.mean(np.sum(adj_matrix,axis=1)))\n",
    "\n",
    "# # setup spatial clusters\n",
    "# cluster_matrix = graph_helpers.generate_clusters_from_lattice(sqrt_n=int(np.sqrt(sim_config['n'])), num_cells_per_dim=sim_config['num_cells_per_dim'])\n",
    "# adj_clusters = np.matmul(adj_matrix,cluster_matrix) \n",
    "# print(np.mean(np.sum(adj_clusters,axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87491dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(graph_helpers)\n",
    "importlib.reload(stats_helpers)\n",
    "\n",
    "########## SPATIAL GRAPH WITH UNIFORM COORDS ##########\n",
    "\n",
    "sim_config.update({\n",
    "    \"n\": 1, \n",
    "    'num_cells_per_dim': 4, # defines spatial partition of unit square used for randomized design\n",
    "    \"kappa\": 0.1, # two nodes interfere (thru reward and transition) if Euclidean dist between coordinates <= kappa \n",
    "})\n",
    "\n",
    "# create interference graph\n",
    "coords_array = graph_helpers.generate_random_points(sim_config['n'])\n",
    "adj_matrix = graph_helpers.build_adjacency_matrix_from_coords(coords_array, sim_config['kappa'])\n",
    "print(np.mean(np.sum(adj_matrix,axis=1)))\n",
    "\n",
    "# setup spatial clusters\n",
    "cluster_matrix = graph_helpers.spatial_clustering_map(coords_array, sim_config['num_cells_per_dim'])\n",
    "adj_clusters = np.matmul(adj_matrix,cluster_matrix) \n",
    "print(np.mean(np.sum(adj_clusters,axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc156973",
   "metadata": {},
   "source": [
    "## 2.2: Initialize MC and find true ATE using Monte Carlo \n",
    "Back to [Table of Contents](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26261f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(mdp_helpers)\n",
    "\n",
    "# initialize Markov chain model\n",
    "n = sim_config['n']\n",
    "T = sim_config['T']\n",
    "max_inventory=(sim_config['num_states']-1)*np.ones(n)\n",
    "C_baseline = np.outer(np.random.random(n), np.ones(T))\n",
    "C_slope = np.ones((n,T)) + 0.2 * np.random.random((n, T))\n",
    "C_lazy = 0.1 * np.ones((n,T))\n",
    "C_alpha = np.random.normal(loc = -5, scale = 2, size = ((n,T)))\n",
    "C_beta = np.random.normal(loc = 10, scale = 4, size = ((n,T)))\n",
    "C_gamma = 0.5*np.random.random((n,T)) * C_beta\n",
    "C_depart = np.random.random((n,T))\n",
    "\n",
    "MC = mdp_helpers.InventoryMarkovChain(\n",
    "    max_inventory=max_inventory,\n",
    "    adj_matrix=adj_matrix,\n",
    "    num_rounds=sim_config['T'],\n",
    "    C_baseline = C_baseline,\n",
    "    C_slope= C_slope,\n",
    "    C_lazy = C_lazy,\n",
    "    C_alpha = C_alpha,\n",
    "    C_beta = C_beta,\n",
    "    C_gamma = C_gamma,\n",
    "    C_depart = C_depart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a9b28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(mdp_helpers)\n",
    "# approximate ATE via Monte Carlo\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "num_sims_apx_ate = 10**4\n",
    "initial_state = sim_config['initial_state']\n",
    "\n",
    "sim_results_0 = MC.simulate_MC(initial_state * np.ones((sim_config['n'])), np.zeros((sim_config['n'], sim_config['T'],num_sims_apx_ate)), use_sigmoid=True)\n",
    "sim_results_1 = MC.simulate_MC(initial_state * np.ones((sim_config['n'])), np.ones((sim_config['n'], sim_config['T'],num_sims_apx_ate)), use_sigmoid=True)\n",
    "\n",
    "all_0_mean = np.mean(sim_results_0[\"rewards\"])\n",
    "all_1_mean = np.mean(sim_results_1[\"rewards\"])\n",
    "\n",
    "print(\"=\"*20 + \" True ATE (apx'ed using Monte Carlo) \" + \"=\"*20)\n",
    "print(f\"Mean reward under all-1 vs. all-0: {all_1_mean:.4f} vs. {all_0_mean:.4f}  \")\n",
    "true_ATE = all_1_mean - all_0_mean\n",
    "print(f\"True ATE: {true_ATE:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c85775",
   "metadata": {},
   "source": [
    "## 2.3: Compute propensity scores\n",
    "Back to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cb5d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(stats_helpers)\n",
    "\n",
    "time_cluster_matrix = stats_helpers.generate_time_blocks(T=sim_config['T'], time_block_length=sim_config['time_block_length'])\n",
    "time_adj_matrix = np.tril(np.ones((sim_config['T'],sim_config['T'])), k=0) - np.tril(np.ones((sim_config['T'],sim_config['T'])), k=-(int(sim_config['recency']) + 1))\n",
    "\n",
    "print(np.mean(np.sum(time_adj_matrix,axis=1)))\n",
    "print(np.mean(np.sum(time_adj_matrix @ time_cluster_matrix > 0,axis=1)))\n",
    "\n",
    "# Compute propensity score (Monte Carlo)\n",
    "\n",
    "arms_tensor = stats_helpers.generate_cluster_treatments(cluster_matrix,time_cluster_matrix,num_W=sim_config['num_W_for_computing_prop'])\n",
    "print(arms_tensor.shape)\n",
    "\n",
    "emp_prop_score_results = stats_helpers.empirical_propensity_scores(arms_tensor,adj_matrix,time_adj_matrix,sim_config['delta'])\n",
    "propensity_1_array, propensity_0_array = emp_prop_score_results['propensity_1'], emp_prop_score_results['propensity_0']\n",
    "\n",
    "print(f\"minimum of emp prop score: {np.amin(propensity_1_array)}, {np.amin(propensity_0_array)}\")\n",
    "print(f\"total number of zeros: {np.count_nonzero(propensity_1_array == 0)}, {np.count_nonzero(propensity_0_array == 0)}\")\n",
    "\n",
    "# Display emp_prop_score_results\n",
    "prop_1_mean, prop_0_mean = propensity_1_array.mean(), propensity_0_array.mean()\n",
    "print(f\"mean emp prop score (interior units): {prop_1_mean:.4f}, {prop_0_mean:.4f}\") \n",
    "n, T = sim_config['n'], sim_config['T']\n",
    "print(f\"expected #(i,t) with X_it=1 is {n*T*prop_1_mean:.2f}, {n*T*prop_0_mean:.2f}\")\n",
    "print(f\"%nz in emp prop_score_0, prop_score_1: {len(np.nonzero(propensity_0_array)[0])/(n*T)*100:.2f}%, {len(np.nonzero(propensity_1_array)[0])/(n*T)*100:.2f}%\")\n",
    "utils.print_time()\n",
    "\n",
    "HT_weights_0 = np.zeros((np.shape(propensity_0_array)))\n",
    "np.divide(1, propensity_0_array, out = HT_weights_0, where=propensity_0_array != 0)\n",
    "print(np.mean(HT_weights_0))\n",
    "print(np.std(HT_weights_0))\n",
    "print(np.amax(HT_weights_0))\n",
    "print(np.amin(HT_weights_0))\n",
    "\n",
    "HT_weights_1 = np.zeros((np.shape(propensity_1_array)))\n",
    "np.divide(1, propensity_1_array, out = HT_weights_1, where=propensity_1_array != 0)\n",
    "print(np.mean(HT_weights_1))\n",
    "print(np.std(HT_weights_1))\n",
    "print(np.amax(HT_weights_1))\n",
    "print(np.amin(HT_weights_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd52978a",
   "metadata": {},
   "source": [
    "## 2.4: Simulate experiment and compute HT and Hajek estimators\n",
    "Back to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41101548",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(stats_helpers)\n",
    "\n",
    "num_iter_sim = 10**5\n",
    "\n",
    "initial_state = sim_config['initial_state']\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "W = stats_helpers.generate_cluster_treatments(cluster_matrix,time_cluster_matrix,num_iter_sim)\n",
    "exposure_results = stats_helpers.exposure_mapping(W, adj_matrix, time_adj_matrix, sim_config['delta'])\n",
    "\n",
    "sim_results = MC.simulate_MC(initial_state * np.ones((sim_config['n'])), W, use_sigmoid=True)\n",
    "rewards = sim_results[\"rewards\"]\n",
    "\n",
    "# rewards_0 = rewards[W == 0]\n",
    "# rewards_1 = rewards[W == 1]\n",
    "# print(np.mean(rewards_0))\n",
    "# print(np.std(rewards_0))\n",
    "# print(np.amax(rewards_0))\n",
    "# print(np.amin(rewards_0))\n",
    "# print(np.mean(rewards_1))\n",
    "# print(np.std(rewards_1))\n",
    "# print(np.amax(rewards_1))\n",
    "# print(np.amin(rewards_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aec0aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK with deteriministic rewards set to be all_0_mean for all control units and all_1_mean for all treated units\n",
    "ht_results = stats_helpers.horvitz_thompson(all_0_mean * (W == 0) + all_1_mean * (W == 1),exposure_results['exposure_1'],exposure_results['exposure_0'],propensity_1_array,propensity_0_array)\n",
    "ate_estimate_ht = ht_results['ate_estimate']\n",
    "\n",
    "print(\"\\n\" + \"=\"*20 + \" Fake Reward Horvitz-Thompson Estimates \" + \"=\"*20)\n",
    "mean_HT_est, var_HT_est = ate_estimate_ht.mean(), ate_estimate_ht.var()\n",
    "print(f\"mean_HT_est: {mean_HT_est:.4f}\\nbias: {mean_HT_est - true_ATE:.4f}\\n\" + f\"var_HT_est: {var_HT_est:.4f}\")\n",
    "\n",
    "# CHECK with the vanilla HT, using exposure mapping as W and 1-W, and ground truth 0.5 propensity scores\n",
    "ht_results = stats_helpers.horvitz_thompson(rewards,W,1-W,0.5*np.ones(propensity_1_array.shape),0.5*np.ones(propensity_0_array.shape))\n",
    "ate_estimate_ht = ht_results['ate_estimate']\n",
    "\n",
    "print(\"\\n\" + \"=\"*20 + \" Vanilla Horvitz-Thompson Estimates \" + \"=\"*20)\n",
    "mean_HT_est, var_HT_est = ate_estimate_ht.mean(), ate_estimate_ht.var()\n",
    "print(f\"mean_HT_est: {mean_HT_est:.4f}\\nbias: {mean_HT_est - true_ATE:.4f}\\n\" + f\"var_HT_est: {var_HT_est:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bb05c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(stats_helpers)\n",
    "\n",
    "#ht_results = stats_helpers.horvitz_thompson(sim_results_0[\"rewards\"] * (W == 0) + sim_results_1[\"rewards\"] * (W == 1),W,1-W,propensity_1_array,propensity_0_array)\n",
    "#ht_results = stats_helpers.horvitz_thompson(sim_results_0_check * (1-W) + sim_results_1_check * W,W,1-W,propensity_1_array,propensity_0_array)\n",
    "#ht_results = stats_helpers.horvitz_thompson(sim_results_0_check * (1-W) + sim_results_1_check * W,exposure_results['exposure_1'],exposure_results['exposure_0'],propensity_1_array,propensity_0_array)\n",
    "ht_results = stats_helpers.horvitz_thompson(rewards,exposure_results['exposure_1'],exposure_results['exposure_0'],propensity_1_array,propensity_0_array)\n",
    "ate_estimate_ht = ht_results['ate_estimate']\n",
    "\n",
    "print(\"\\n\" + \"=\"*20 + \" Horvitz-Thompson Estimates \" + \"=\"*20)\n",
    "mean_HT_est, var_HT_est = ate_estimate_ht.mean(), ate_estimate_ht.var()\n",
    "print(f\"mean_HT_est: {mean_HT_est:.4f}\\nbias: {mean_HT_est - true_ATE:.4f}\\n\" + f\"var_HT_est: {var_HT_est:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9468480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(stats_helpers)\n",
    "\n",
    "#hajek_results = stats_helpers.hajek(all_0_mean * (W == 0) + all_1_mean * (W == 1),exposure_results['exposure_1'],exposure_results['exposure_0'],propensity_1_array,propensity_0_array)\n",
    "#hajek_results = stats_helpers.hajek(temp_1[\"rewards\"],exposure_results['exposure_1'],exposure_results['exposure_0'],propensity_1_array,propensity_0_array)\n",
    "hajek_results = stats_helpers.hajek(rewards,exposure_results['exposure_1'],exposure_results['exposure_0'],propensity_1_array,propensity_0_array)\n",
    "ate_estimate_hajek = hajek_results['ate_estimate']\n",
    "\n",
    "print(\"\\n\" + \"=\"*20 + \" Hajek Estimates \" + \"=\"*20)\n",
    "mean_Hajek_est, var_Hajek_est = ate_estimate_hajek.mean(), ate_estimate_hajek.var()\n",
    "print(f\"mean_HT_est: {mean_Hajek_est:.4f}\\nbias: {mean_Hajek_est - true_ATE:.4f}\\n\" + f\"var_Hajek_est: {var_Hajek_est:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b786a8c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba14067",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(stats_helpers)\n",
    "\n",
    "burn_in = 2\n",
    "DM_results = stats_helpers.diff_means(rewards,W, sim_config['time_block_length'], burn_in)\n",
    "ate_estimate_DM = DM_results['ate_estimate']\n",
    "\n",
    "print(\"\\n\" + \"=\"*20 + \" Diff-in-Means Estimates \" + \"=\"*20)\n",
    "mean_DM_est, var_DM_est = ate_estimate_DM.mean(), ate_estimate_DM.var()\n",
    "print(f\"mean_DM_est: {mean_DM_est:.4f}\\nbias: {mean_DM_est - true_ATE:.4f}\\n\" + f\"var_DM_est: {var_DM_est:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
